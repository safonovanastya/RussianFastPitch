{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastPitch: Voice Modification with Custom Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [FastPitch](https://arxiv.org/abs/2006.06873) model is based on the [FastSpeech](https://arxiv.org/abs/1905.09263) model. Similarly to [FastSpeech2](https://arxiv.org/abs/2006.04558), which has been developed concurrently, it learns to predict the pitch contour and conditions the generation on such contour.\n",
    "\n",
    "The simple mechanism of predicting the pitch on grapheme-level (rather than frame-level, as FastSpeech2 does) allows to easily alter the pitch during synthesis. FastPitch can thus change the perceived emotional state of the speaker, or slightly emphasise certain lexical units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the notebook inside the container. By default the container forwards port `8888`.\n",
    "```\n",
    "bash scripts/docker/interactive.sh\n",
    "\n",
    "# inside the container\n",
    "cd notebooks\n",
    "jupyter notebook --ip='*' --port=8888\n",
    "```\n",
    "Please refer the Requirement section in `README.md` for more details and running outside the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.getcwd().split('/')[-1] == 'notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate audio samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a FastPitch model from scrath takes 3 to 27 hours depending on the type and number of GPUs, performance numbers can be found in Section \"Training performance results\" in `README.md`. Therefore, to save the time of running this notebook, we recommend to download the pretrained FastPitch checkpoints on NGC for inference.\n",
    "\n",
    "You can find FP32 checkpoint at [NGC](https://ngc.nvidia.com/catalog/models/nvidia:fastpitch_pyt_fp32_ckpt_v1/files) , and AMP (Automatic Mixed Precision) checkpoint at [NGC](https://ngc.nvidia.com/catalog/models/nvidia:fastpitch_pyt_amp_ckpt_v1/files).\n",
    "\n",
    "To synthesize audio, you will need a WaveGlow model, which generates waveforms based on mel-spectrograms generated by FastPitch.You can download a pre-trained WaveGlow AMP model at [NGC](https://ngc.nvidia.com/catalog/models/nvidia:waveglow256pyt_fp16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform inference using the respective checkpoints that are passed as `--fastpitch` and `--waveglow` arguments. Next, you will use FastPitch model to generate audio samples for input text, including the basic version and the variations i npace, fade out, and pitch transforms, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "# store paths in aux variables\n",
    "fastp = '../output_fastpitch/FastPitch_checkpoint_1000.pt'\n",
    "waveg = '../output_waveglow/checkpoint_WaveGlow_450.pt'\n",
    "flags = f'--cuda --fastpitch {fastp} --waveglow {waveg} --wn-channels 256 --p-arpabet 0.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic speech synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to create an input file with some text, or just input the text in the below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile text.txt\n",
    "В выходны+е со мной бы+ли Мару+ся, Ка+тя и Мари+на."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../inference.py {flags} -i text.txt -o ../output/original_ik4 > /dev/null\n",
    "\n",
    "IPython.display.Audio(\"../output/original_ik4/audio_0.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bryzgunova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../fastpitch/pitch_transform.py\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def is_sound(symb):\n",
    "    return (ord('а') <= ord(symb) <= ord('ё')) or (ord('А') <= ord(symb) <= ord('Ё'))\n",
    "\n",
    "\n",
    "def pitch_transform_custom(pitch, pitch_lens, text, ik_index):\n",
    "    accent = text[0].find('++') - 1\n",
    "    second_accent = text[0].rfind('++') - 1\n",
    "    scale = 20\n",
    "    phrase_pitch = pitch[0]\n",
    "    average = torch.median(phrase_pitch)\n",
    "    pitch[0] = (pitch[0] - average) / 1.5 + average\n",
    "    smoothed_values = []\n",
    "    for i in range(len(text[0])):\n",
    "        new_value = (pitch[0][0,max(0, i - 1)] + pitch[0][0,i] + pitch[0][0,min(i, len(text[0]) - 1)]) / 3\n",
    "        smoothed_values.append(new_value)\n",
    "        \n",
    "    for i in range(len(text[0])):\n",
    "        pitch[0][0,i] = smoothed_values[i]\n",
    "    \n",
    "    low_border, upper_border = 80, 300\n",
    "\n",
    "    \n",
    "    pitch_change = {\n",
    "        1: {\n",
    "            'beginning': 0, \n",
    "            'before': [0, 0, -.2 * scale], \n",
    "            'accent': -.5 * scale, \n",
    "            'after': [-1 * scale, -1 * scale], \n",
    "            'end': 0\n",
    "        },\n",
    "        2: {\n",
    "            'beginning': 0, \n",
    "            'before': [0, 1 * scale, 1.5 * scale], \n",
    "            'accent': -1 * scale, \n",
    "            'after': [-0.5 * scale, -0.5 * scale], \n",
    "            'end': -0.5 * scale,\n",
    "        },\n",
    "        3: {\n",
    "            'beginning': 0, \n",
    "            'before': [-1 * scale, -1 * scale, 2 * scale], \n",
    "            'accent': 2 * scale, \n",
    "            'after': [1 * scale, 1 * scale], \n",
    "            'end': 0,\n",
    "        },\n",
    "        4: {\n",
    "            'beginning': 0, \n",
    "            'before': [scale, scale, -1.5 * scale], \n",
    "            'accent': -1.5 * scale, \n",
    "            'after': [1.5 * scale, 1.5 * scale], \n",
    "            'end': 0,\n",
    "        },\n",
    "        5: {\n",
    "            'beginning': 0, \n",
    "            'before': [0, 0, 2 * scale], \n",
    "            'accent_1': 3 * scale, \n",
    "            'accent_2': -1 * scale, \n",
    "            'after': [0 * scale, 0 * scale], \n",
    "            'end': 0,\n",
    "        },\n",
    "        6: {\n",
    "            'beginning': 0, \n",
    "            'before': [0, - scale, scale], \n",
    "            'accent': 2.5 * scale, \n",
    "            'after': [2 * scale, 2 * scale], \n",
    "            'end': 2 * scale,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if accent == second_accent:\n",
    "        if ik_index == 5:\n",
    "            print('Этот тип интонационной конструкции подразумевает один акцент. Пожалуйста, поставьте один акцент во фразе.')\n",
    "        \n",
    "        pitch[0][0, accent] += pitch_change[ik_index]['accent']\n",
    "\n",
    "        sound_number = 0\n",
    "        for i in range(accent - 1, -1, -1):\n",
    "            if sound_number <= 2:\n",
    "                pitch[0][0, i] += pitch_change[ik_index]['before'][2 - sound_number]\n",
    "                if is_sound(text[0][i]):\n",
    "                    sound_number += 1\n",
    "            else:\n",
    "                pitch[0][0, i] += pitch_change[ik_index]['beginning']\n",
    "        sound_number = 0  \n",
    "        for i in range(accent + 1, len(text[0])):\n",
    "            if sound_number <= 1:\n",
    "                pitch[0][0, i] += pitch_change[ik_index]['after'][sound_number]\n",
    "                if is_sound(text[0][i]):\n",
    "                    sound_number += 1\n",
    "            else:\n",
    "                pitch[0][0, i] += pitch_change[ik_index]['end']\n",
    "        for i in range(len(text[0])):\n",
    "            pitch[0][0, i] = max(80, pitch[0][0, i])\n",
    "    else:\n",
    "        if ik_index != 5:\n",
    "            print('Этот тип интонационной конструкции подразумевает два акцента. Пожалуйста, поставьте два акцента во фразе.')\n",
    "            \n",
    "        cons = 0\n",
    "        for i in range(accent, second_accent):\n",
    "            pitch[0][0, i] += pitch_change[ik_index]['accent_1'] - cons\n",
    "            cons += 3\n",
    "        pitch[0][0, second_accent] += pitch_change[ik_index]['accent_2']\n",
    "\n",
    "        sound_number = 0\n",
    "        for i in range(accent - 1, -1, -1):\n",
    "            if sound_number <= 2:\n",
    "                pitch[0][0, i] += pitch_change[ik_index]['before'][2 - sound_number]\n",
    "                    if is_sound(text[0][i]):\n",
    "                sound_number += 1\n",
    "            else:\n",
    "                pitch[0][0, i] += pitch_change[ik_index]['beginning']\n",
    "        sound_number = 0  \n",
    "        for i in range(second_accent + 1, len(text[0])):\n",
    "            if sound_number <= 1:\n",
    "                pitch[0][0, i] += pitch_change[ik_index]['after'][sound_number]\n",
    "                if is_sound(text[0][i]):\n",
    "                    sound_number += 1\n",
    "            else:\n",
    "                pitch[0][0, i] += pitch_change[ik_index]['end']\n",
    "        for i in range(len(text[0])):\n",
    "            pitch[0][0, i] = max(80, pitch[0][0, i])\n",
    "        \n",
    "    # smooth non-sounds\n",
    "    for i, symb in enumerate(text[0]):\n",
    "        if not is_sound(symb):\n",
    "            has_left_sound, has_right_sound = False, False\n",
    "            for j in range(i, -1, -1):\n",
    "                if is_sound(text[0][j]):\n",
    "                    left_sound = pitch[0][0, j]\n",
    "                    has_left_sound = True\n",
    "                    break\n",
    "            for j in range(i, len(text[0])):\n",
    "                if is_sound(text[0][j]):\n",
    "                    right_sound = pitch[0][0, j]\n",
    "                    has_right_sound = True\n",
    "                    break\n",
    "            \n",
    "            if has_left_sound:\n",
    "                pitch[0][0, i] = left_sound\n",
    "            elif has_right_sound:\n",
    "                pitch[0][0, i] = right_sound\n",
    "    \n",
    "    return pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../inference.py {flags} -i text.txt -o ../output/modified_ik4/ \\\n",
    "    --pitch-transform-custom 4\n",
    "\n",
    "IPython.display.Audio(\"../output/modified_ik4/audio_0.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
